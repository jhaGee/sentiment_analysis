{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sentiment_analysis_01JAN.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1UiAPLM5L7eAQoZG8Zp8jCfQhByeKUpLg","authorship_tag":"ABX9TyOMVqJn3occqPqQS9tRBbJu"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tAo1SUorxdxy","executionInfo":{"status":"ok","timestamp":1609789016097,"user_tz":-330,"elapsed":1199,"user":{"displayName":"Sanjeev Jha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHsC0nopnKGXI1cXGryzBvdLCdtsejhtYPMgbf=s64","userId":"05136766889113112751"}},"outputId":"20f2fe0b-820b-4803-85e0-fc2650cea636"},"source":["import numpy as np\r\n","import keras as K\r\n","import tensorflow as tf\r\n","\r\n","from keras.preprocessing.sequence import pad_sequences\r\n","from keras.models import Sequential\r\n","from keras.layers import Embedding, LSTM\r\n","\r\n","import numpy as np\r\n","\r\n","import keras\r\n","from keras.preprocessing import sequence\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense, Embedding\r\n","from keras.layers import LSTM\r\n","from keras.datasets import imdb\r\n","\r\n","print(\"Sentiment Analysis on IMDB data set with keras\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Sentiment Analysis on IMDB data set with keras\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OUtddKOZyHth"},"source":["# Load Data ...\r\n","\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kiol0VYNyKgy","executionInfo":{"status":"ok","timestamp":1609789142456,"user_tz":-330,"elapsed":6388,"user":{"displayName":"Sanjeev Jha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHsC0nopnKGXI1cXGryzBvdLCdtsejhtYPMgbf=s64","userId":"05136766889113112751"}},"outputId":"6accf6d1-1e4e-4ac5-fd9d-bbd35c431847"},"source":["max_words= 25000\r\n","print(\"Loading Data .....\")\r\n","(train_x, train_y), (test_x,test_y)= K.datasets.imdb.load_data(num_words=max_words)\r\n","\r\n","print(train_x[0:5])\r\n","print(train_y[0:5])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Loading Data .....\n"],"name":"stdout"},{"output_type":"stream","text":["<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"],"name":"stderr"},{"output_type":"stream","text":["[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n"," list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 23141, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n"," list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n"," list([1, 4, 18609, 16085, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 15305, 744, 35, 3715, 761, 61, 5766, 452, 9214, 4, 985, 7, 2, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 2, 7339, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 6004, 4, 1615, 5, 23005, 7, 5168, 17, 13, 7064, 12, 19, 6, 464, 31, 314, 11, 2, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 18435, 192, 5, 1219, 3890, 19, 20523, 217, 4122, 1710, 537, 20341, 1236, 5, 736, 10, 10, 61, 403, 9, 2, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 9225, 145, 143, 5122, 12, 7039, 537, 746, 537, 537, 15, 7979, 4, 18665, 594, 7, 5168, 94, 9096, 3987, 15242, 11, 2, 4, 538, 7, 1795, 246, 2, 9, 10161, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 6307, 10197, 19, 49, 7, 4, 1885, 13699, 1118, 25, 80, 126, 842, 10, 10, 2, 18223, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 16376, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 2, 21, 29, 9, 2841, 23, 4, 1010, 2, 793, 6, 13699, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 16376, 8, 124, 4, 882, 4, 882, 496, 27, 2, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 11120, 1311, 8, 4, 23643, 7, 31, 7, 2, 91, 22793, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 11876, 1775, 3353, 12716, 1846, 4, 11286, 7, 154, 5, 4, 518, 53, 13243, 11286, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 18223, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 2, 4, 22793, 10359, 9, 242, 4, 91, 1202, 11377, 5, 2070, 307, 22, 7, 5168, 126, 93, 40, 18223, 13, 188, 1076, 3222, 19, 4, 13465, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 18223, 13, 2, 14, 280, 13, 219, 4, 2, 431, 758, 859, 4, 953, 1052, 12283, 7, 5991, 5, 94, 40, 25, 238, 60, 2, 4, 15812, 804, 2, 7, 4, 9941, 132, 8, 67, 6, 22, 15, 9, 283, 8, 5168, 14, 31, 9, 242, 955, 48, 25, 279, 22148, 23, 12, 1685, 195, 25, 238, 60, 796, 13713, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 7008, 15, 566, 30, 579, 21, 64, 2574])\n"," list([1, 249, 1323, 7, 61, 113, 10, 10, 13, 1637, 14, 20, 56, 33, 2401, 18, 457, 88, 13, 2626, 1400, 45, 3171, 13, 70, 79, 49, 706, 919, 13, 16, 355, 340, 355, 1696, 96, 143, 4, 22, 32, 289, 7, 61, 369, 71, 2359, 5, 13, 16, 131, 2073, 249, 114, 249, 229, 249, 20, 13, 28, 126, 110, 13, 473, 8, 569, 61, 419, 56, 429, 6, 1513, 18, 35, 534, 95, 474, 570, 5, 25, 124, 138, 88, 12, 421, 1543, 52, 725, 6397, 61, 419, 11, 13, 1571, 15, 1543, 20, 11, 4, 22016, 5, 296, 12, 3524, 5, 15, 421, 128, 74, 233, 334, 207, 126, 224, 12, 562, 298, 2167, 1272, 7, 2601, 5, 516, 988, 43, 8, 79, 120, 15, 595, 13, 784, 25, 3171, 18, 165, 170, 143, 19, 14, 5, 7224, 6, 226, 251, 7, 61, 113])]\n","[1 0 0 1 0]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"cx7z_fQv0JL7"},"source":["# Pre Processing"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gOEzD77g0M2W","executionInfo":{"status":"ok","timestamp":1609789232385,"user_tz":-330,"elapsed":1203,"user":{"displayName":"Sanjeev Jha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHsC0nopnKGXI1cXGryzBvdLCdtsejhtYPMgbf=s64","userId":"05136766889113112751"}},"outputId":"2374adfe-3470-4381-ac5b-d9d5612d0ca9"},"source":["max_review_length=160\r\n","train_x=K.preprocessing.sequence.pad_sequences(train_x, truncating='pre',\r\n","                                               padding='pre',maxlen=max_review_length)\r\n","test_x=K.preprocessing.sequence.pad_sequences(test_x, truncating='pre',\r\n","                                               padding='pre',maxlen=max_review_length)\r\n","print(train_x[0:5])\r\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[[   14    22     4  1920  4613   469     4    22    71    87    12    16\n","     43   530    38    76    15    13  1247     4    22    17   515    17\n","     12    16   626    18 19193     5    62   386    12     8   316     8\n","    106     5     4  2223  5244    16   480    66  3785    33     4   130\n","     12    16    38   619     5    25   124    51    36   135    48    25\n","   1415    33     6    22    12   215    28    77    52     5    14   407\n","     16    82 10311     8     4   107   117  5952    15   256     4     2\n","      7  3766     5   723    36    71    43   530   476    26   400   317\n","     46     7     4 12118  1029    13   104    88     4   381    15   297\n","     98    32  2071    56    26   141     6   194  7486    18     4   226\n","     22    21   134   476    26   480     5   144    30  5535    18    51\n","     36    28   224    92    25   104     4   226    65    16    38  1334\n","     88    12    16   283     5    16  4472   113   103    32    15    16\n","   5345    19   178    32]\n"," [  110  3103    21    14    69   188     8    30    23     7     4   249\n","    126    93     4   114     9  2300  1523     5   647     4   116     9\n","     35  8163     4   229     9   340  1322     4   118     9     4   130\n","   4901    19     4  1002     5    89    29   952    46    37     4   455\n","      9    45    43    38  1543  1905   398     4  1649    26  6853     5\n","    163    11  3215 10156     4  1153     9   194   775     7  8255 11596\n","    349  2637   148   605 15358  8003    15   123   125    68 23141  6853\n","     15   349   165  4362    98     5     4   228     9    43     2  1157\n","     15   299   120     5   120   174    11   220   175   136    50     9\n","   4373   228  8255     5     2   656   245  2350     5     4  9837   131\n","    152   491    18     2    32  7464  1212    14     9     6   371    78\n","     22   625    64  1382     9     8   168   145    23     4  1690    15\n","     16     4  1355     5    28     6    52   154   462    33    89    78\n","    285    16   145    95]\n"," [    0     0     0     0     0     0     0     0     0     0     0     0\n","      0     0     0     0     0     0     0     1    14    47     8    30\n","     31     7     4   249   108     7     4  5974    54    61   369    13\n","     71   149    14    22   112     4  2401   311    12    16  3711    33\n","     75    43  1829   296     4    86   320    35   534    19   263  4821\n","   1301     4  1873    33    89    78    12    66    16     4   360     7\n","      4    58   316   334    11     4  1716    43   645   662     8   257\n","     85  1200    42  1228  2578    83    68  3912    15    36   165  1539\n","    278    36    69     2   780     8   106    14  6905  1338    18     6\n","     22    12   215    28   610    40     6    87   326    23  2300    21\n","     23    22    12   272    40    57    31    11     4    22    47     6\n","   2307    51     9   170    23   595   116   595  1352    13   191    79\n","    638    89     2    14     9     8   106   607   624    35   534     6\n","    227     7   129   113]\n"," [   14    65    44   537    75 11876  1775  3353 12716  1846     4 11286\n","      7   154     5     4   518    53 13243 11286     7  3211   882    11\n","    399    38    75   257  3807    19 18223    17    29   456     4    65\n","      7    27   205   113    10    10     2     4 22793 10359     9   242\n","      4    91  1202 11377     5  2070   307    22     7  5168   126    93\n","     40 18223    13   188  1076  3222    19     4 13465     7  2348   537\n","     23    53   537    21    82    40 18223    13     2    14   280    13\n","    219     4     2   431   758   859     4   953  1052 12283     7  5991\n","      5    94    40    25   238    60     2     4 15812   804     2     7\n","      4  9941   132     8    67     6    22    15     9   283     8  5168\n","     14    31     9   242   955    48    25   279 22148    23    12  1685\n","    195    25   238    60   796 13713     4   671     7  2804     5     4\n","    559   154   888     7   726    50    26    49  7008    15   566    30\n","    579    21    64  2574]\n"," [    0     0     0     0     0     0     0     0     0     0     0     0\n","      0     1   249  1323     7    61   113    10    10    13  1637    14\n","     20    56    33  2401    18   457    88    13  2626  1400    45  3171\n","     13    70    79    49   706   919    13    16   355   340   355  1696\n","     96   143     4    22    32   289     7    61   369    71  2359     5\n","     13    16   131  2073   249   114   249   229   249    20    13    28\n","    126   110    13   473     8   569    61   419    56   429     6  1513\n","     18    35   534    95   474   570     5    25   124   138    88    12\n","    421  1543    52   725  6397    61   419    11    13  1571    15  1543\n","     20    11     4 22016     5   296    12  3524     5    15   421   128\n","     74   233   334   207   126   224    12   562   298  2167  1272     7\n","   2601     5   516   988    43     8    79   120    15   595    13   784\n","     25  3171    18   165   170   143    19    14     5  7224     6   226\n","    251     7    61   113]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l8tftWBI7SmY"},"source":["# Define the MODEL\r\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fgE7cfkY7cZj","executionInfo":{"status":"ok","timestamp":1609789289649,"user_tz":-330,"elapsed":2765,"user":{"displayName":"Sanjeev Jha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHsC0nopnKGXI1cXGryzBvdLCdtsejhtYPMgbf=s64","userId":"05136766889113112751"}},"outputId":"b3abec7d-6a6a-4a81-b9e8-bcbfba9ac48b"},"source":["embedding_length = 64\r\n","model = Sequential()\r\n","model.add(Embedding(input_dim=max_words, output_dim=embedding_length, input_length=max_review_length))\r\n","model.add(LSTM(units=64, input_shape=(max_review_length, embedding_length), return_sequences=False, unroll=True))\r\n","model.add(Dense(1, activation='sigmoid'))\r\n","model.compile(loss='binary_crossentropy',\r\n","              optimizer='adam',\r\n","              metrics=['accuracy'])\r\n","model.summary()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 160, 64)           1600000   \n","_________________________________________________________________\n","lstm_3 (LSTM)                (None, 64)                33024     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 1,633,089\n","Trainable params: 1,633,089\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S0Dm843zO2IV"},"source":["# Train the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZlbkthQ1PAxQ","executionInfo":{"status":"ok","timestamp":1609789960402,"user_tz":-330,"elapsed":668262,"user":{"displayName":"Sanjeev Jha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHsC0nopnKGXI1cXGryzBvdLCdtsejhtYPMgbf=s64","userId":"05136766889113112751"}},"outputId":"0ee14a29-2071-41ea-e873-e3a93b8e0d05"},"source":["print('Training...')\r\n","batch_size = 32\r\n","model.fit(train_x, train_y,\r\n","          batch_size = batch_size,\r\n","          epochs=10,\r\n","          validation_data = (test_x, test_y))\r\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Training...\n","Epoch 1/10\n","782/782 [==============================] - 88s 85ms/step - loss: 0.5132 - accuracy: 0.7256 - val_loss: 0.3242 - val_accuracy: 0.8679\n","Epoch 2/10\n","782/782 [==============================] - 64s 82ms/step - loss: 0.1956 - accuracy: 0.9257 - val_loss: 0.3644 - val_accuracy: 0.8561\n","Epoch 3/10\n","782/782 [==============================] - 64s 82ms/step - loss: 0.1168 - accuracy: 0.9610 - val_loss: 0.3882 - val_accuracy: 0.8487\n","Epoch 4/10\n","782/782 [==============================] - 64s 82ms/step - loss: 0.0816 - accuracy: 0.9734 - val_loss: 0.4693 - val_accuracy: 0.8566\n","Epoch 5/10\n","782/782 [==============================] - 64s 82ms/step - loss: 0.0477 - accuracy: 0.9857 - val_loss: 0.5772 - val_accuracy: 0.8445\n","Epoch 6/10\n","782/782 [==============================] - 64s 82ms/step - loss: 0.0422 - accuracy: 0.9848 - val_loss: 0.6135 - val_accuracy: 0.8504\n","Epoch 7/10\n","782/782 [==============================] - 64s 82ms/step - loss: 0.0266 - accuracy: 0.9912 - val_loss: 0.6299 - val_accuracy: 0.8453\n","Epoch 8/10\n","782/782 [==============================] - 65s 83ms/step - loss: 0.0235 - accuracy: 0.9937 - val_loss: 0.7450 - val_accuracy: 0.8442\n","Epoch 9/10\n","782/782 [==============================] - 64s 82ms/step - loss: 0.0158 - accuracy: 0.9956 - val_loss: 0.7831 - val_accuracy: 0.8473\n","Epoch 10/10\n","782/782 [==============================] - 64s 82ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.7505 - val_accuracy: 0.8470\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7736b0c668>"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"B-iDwr3fWvph"},"source":["# Evaluate the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-V_c0WujWzms","executionInfo":{"status":"ok","timestamp":1609789978950,"user_tz":-330,"elapsed":15221,"user":{"displayName":"Sanjeev Jha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHsC0nopnKGXI1cXGryzBvdLCdtsejhtYPMgbf=s64","userId":"05136766889113112751"}},"outputId":"8e48e661-06c3-4bcf-c304-1356b8715957"},"source":["score, acc = model.evaluate(test_x,test_y, batch_size=batch_size)\r\n","print(f'Test score = {score}')\r\n","print(f'Test accuracy = {acc}')\r\n","model.save('/content/drive/MyDrive/Caption/model.h5')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["782/782 [==============================] - 12s 16ms/step - loss: 0.7505 - accuracy: 0.8470\n","Test score = 0.7504640817642212\n","Test accuracy = 0.8469600081443787\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ebG-L4Isc_4r"},"source":["# Making predictions with model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3iW4bQ6vdFZW","executionInfo":{"status":"ok","timestamp":1609790003627,"user_tz":-330,"elapsed":2758,"user":{"displayName":"Sanjeev Jha","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhHsC0nopnKGXI1cXGryzBvdLCdtsejhtYPMgbf=s64","userId":"05136766889113112751"}},"outputId":"65fb8196-3b30-4320-da27-307b68f396d1"},"source":["review = \"I love cat.\"\r\n","print(f'New review = {review}')\r\n","\r\n","d = imdb.get_word_index()\r\n","words = review.split()\r\n","review = []\r\n","\r\n","for word in words:\r\n","  if word not in d:\r\n","    review.append(2)\r\n","  else:\r\n","    review.append(d[word] + 3)\r\n","  \r\n","print(f\"review = {review}\")\r\n","\r\n","review = sequence.pad_sequences([review], truncating='pre', padding='pre', maxlen=80)\r\n","\r\n","prediction = model.predict(review)\r\n","print(f'Prediction (0 = Negative, 1 = positive) = {prediction}')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["New review = I love cat.\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n","1646592/1641221 [==============================] - 0s 0us/step\n","review = [2, 119, 2]\n","WARNING:tensorflow:Model was constructed with shape (None, 160) for input KerasTensor(type_spec=TensorSpec(shape=(None, 160), dtype=tf.float32, name='embedding_3_input'), name='embedding_3_input', description=\"created by layer 'embedding_3_input'\"), but it was called on an input with incompatible shape (None, 80).\n","Prediction (0 = Negative, 1 = positive) = [[0.88790345]]\n"],"name":"stdout"}]}]}